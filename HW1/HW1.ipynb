{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dbamman/nlp23/blob/main/HW1/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Featurized Models for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we provide an implementation of a simple binary classifier that will predict the sentiment of a movie review based on a group of original features -- provided by you! \n",
    "\n",
    "Before diving into any code, please read through the associated [PDF](https://github.com/dbamman/nlp23/blob/main/HW1/HW1.pdf) for an overview of the assignment and specific instructions on how to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TQTT9x-6d2JI"
   },
   "outputs": [],
   "source": [
    "import sys, argparse\n",
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import operator\n",
    "import nltk\n",
    "import csv\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import option_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4KuVSCSqlUX",
    "outputId": "f4cf377b-6d74-473c-a945-828fa09bae92"
   },
   "outputs": [],
   "source": [
    "# !python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro: Gather Data + Create Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hk07KCgwoZy"
   },
   "source": [
    "Let's download the data we'll use for training and development, and also the data we'll make predictions with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hn0XtfFeqP2P",
    "outputId": "1a9b6900-5a62-4341-a6ba-bf280a361346"
   },
   "outputs": [],
   "source": [
    "### Commenting out since working locally\n",
    "#  # Get data\n",
    "# !wget https://raw.githubusercontent.com/dbamman/nlp23/main/HW1/train.txt\n",
    "# !wget https://raw.githubusercontent.com/dbamman/nlp23/main/HW1/dev.txt\n",
    "# !wget https://raw.githubusercontent.com/dbamman/nlp23/main/HW1/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jq2yq0xpRCUb"
   },
   "outputs": [],
   "source": [
    "trainingFile = \"train.txt\"\n",
    "evaluationFile = \"dev.txt\"\n",
    "testFile = \"test.txt\"\n",
    "\n",
    "lexiconFile = \"subjclueslen1-HLTEMNLP05.tff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Classifier class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we've created a Binary Classifier. This class will let us learn the traits associated with positive and negatively classed movie reviews in order to make predictions on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "CGiM8qQiJOBU"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code.\n",
    "## This defines the classification class which\n",
    "## loads the data and sets up the model.\n",
    "######################################################################\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    def __init__(self, feature_method, L2_regularization_strength=1.0, min_feature_count=1):\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.log_reg = None\n",
    "        self.L2_regularization_strength=L2_regularization_strength\n",
    "        self.min_feature_count=min_feature_count\n",
    "\n",
    "        self.trainX, self.trainY, self.trainOrig = self.process(trainingFile, training=True)\n",
    "        self.devX, self.devY, self.devOrig = self.process(evaluationFile, training=False)\n",
    "        self.testX, _, self.testOrig = self.process(testFile, training=False)\n",
    "\n",
    "    # Read data from file\n",
    "    def load_data(self, filename):\n",
    "        data = []\n",
    "        with open(filename, encoding=\"utf8\") as file:\n",
    "            for line in file:\n",
    "                cols = line.split(\"\\t\")\n",
    "                idd = cols[0]\n",
    "                label = cols[1]\n",
    "                text = cols[2]\n",
    "\n",
    "                data.append((idd, label, text))\n",
    "                \n",
    "        return data\n",
    "\n",
    "    # Featurize entire dataset\n",
    "    def featurize(self, data):\n",
    "        featurized_data = []\n",
    "        for idd, label, text in data:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append((label, feats))\n",
    "        return featurized_data\n",
    "\n",
    "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
    "    def process(self, dataFile, training = False):\n",
    "        original_data = self.load_data(dataFile)\n",
    "        data = self.featurize(original_data)\n",
    "\n",
    "        if training:\n",
    "            fid = 0\n",
    "            feature_doc_count = Counter()\n",
    "            for label, feats in data:\n",
    "                for feat in feats:\n",
    "                    feature_doc_count[feat]+= 1\n",
    "\n",
    "            for feat in feature_doc_count:\n",
    "                if feature_doc_count[feat] >= self.min_feature_count:\n",
    "                    self.feature_vocab[feat] = fid\n",
    "                    fid += 1\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        Y = [None]*D\n",
    "        for idx, (label, feats) in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "            Y[idx] = label\n",
    "\n",
    "        return X, Y, original_data\n",
    "\n",
    "    def load_test(self, dataFile):\n",
    "        data = self.load_data(dataFile)\n",
    "        data = self.featurize(data)\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        Y = [None]*D\n",
    "        for idx, (data_id, feats) in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "            Y[idx] = data_id\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    # Train model and evaluate on held-out data\n",
    "    def evaluate(self):\n",
    "        (D,F) = self.trainX.shape\n",
    "        self.log_reg = linear_model.LogisticRegression(C = self.L2_regularization_strength, max_iter=1000)\n",
    "        self.log_reg.fit(self.trainX, self.trainY)\n",
    "        training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
    "        development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
    "        print(\"Method: %s, Features: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (self.feature_method.__name__, F, training_accuracy, development_accuracy))\n",
    "\n",
    "\n",
    "    # Predict labels for new data\n",
    "    def predict(self):\n",
    "        predX = self.log_reg.predict(self.testX)\n",
    "\n",
    "        with open(\"%s_%s\" % (self.feature_method.__name__, \"predictions.csv\"), \"w\", encoding=\"utf8\") as out:\n",
    "            writer=csv.writer(out)\n",
    "            writer.writerow([\"Id\", \"Expected\"])\n",
    "            for idx, data_id in enumerate(self.testX):\n",
    "                writer.writerow([self.testOrig[idx][0], predX[idx]])\n",
    "        out.close()\n",
    "\n",
    "\n",
    "    def printWeights(self, n=10):\n",
    "\n",
    "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
    "        for k in self.feature_vocab:\n",
    "            reverse_vocab[self.feature_vocab[k]]=k\n",
    "\n",
    "        # binary\n",
    "        if len(self.log_reg.classes_) == 2:\n",
    "              weights=self.log_reg.coef_[0]\n",
    "\n",
    "              cat=self.log_reg.classes_[1]\n",
    "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "              cat=self.log_reg.classes_[0]\n",
    "              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "        # multiclass\n",
    "        else:\n",
    "          for i, cat in enumerate(self.log_reg.classes_):\n",
    "\n",
    "              weights=self.log_reg.coef_[i]\n",
    "\n",
    "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Classifier example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDmfkG782kgo"
   },
   "source": [
    "Let's create an initial classifier based on a really simple feature using a dictionary: \n",
    "\n",
    "* if the abstract contains the words \"love\" or \"like\", the `contains_positive_word` feature will fire, and \n",
    "* if it contains either \"hate\" or \"dislike\", the `contains_negative_word` will fire.  \n",
    "\n",
    "Note how we use `nltk.word_tokenize` to tokenize the text into its discrete words (the documentation for which can be found [here](https://www.nltk.org/api/nltk.tokenize.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xCq1bL3e2jUj"
   },
   "outputs": [],
   "source": [
    "def simple_featurize(text):\n",
    "    feats = {}\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word == \"love\" or word == \"like\":\n",
    "            feats[\"contains_positive_word\"] = 1\n",
    "        if word == \"hate\" or word == \"dislike\":\n",
    "            feats[\"contains_negative_word\"] = 1\n",
    "            \n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3PQdN9r3Ujz"
   },
   "source": [
    "Now let's see how that feature performs on the development data. \n",
    "\n",
    "Note the `L2_regularization_strength` parameter specifies the strength of the L2 regularizer (values closer to 0 = stronger regularization), and `min_feature_count` specifies how many data points need to contain a feature for it to be passed into the model as a feature. Both are ways to prevent the model from overfitting and achieve higher performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jnqjxd6fKPiP",
    "outputId": "b17b382f-a566-4b0e-b8ca-ae95dc20ec45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: simple_featurize, Features: 2, Train accuracy: 0.509, Dev accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "simple_classifier = Classifier(simple_featurize, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "simple_classifier.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO4XQzU3PdeU"
   },
   "source": [
    "So we've created a classifier. But is its accuracy score any good?  Let's calculate the accuracy of a \"majority classifier\" to provide some context. This determines the most-represented (majority) class in the training data, and then predicts every test point to be this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t--LfOjPj7T",
    "outputId": "36ed0df5-ac40-4370-b32e-1029e3a21afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: pos\tDev accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "def majority_class(trainY, devY):\n",
    "    labelCounts=Counter()\n",
    "    for label in trainY:\n",
    "        labelCounts[label]+=1\n",
    "    majority_class=labelCounts.most_common(1)[0][0]\n",
    "\n",
    "    correct=0.\n",
    "    for label in devY:\n",
    "        if label == majority_class:\n",
    "            correct+=1\n",
    "            \n",
    "    print(\"Majority class: %s\\tDev accuracy: %.3f\" % (majority_class, correct/len(devY)))\n",
    "majority_class(simple_classifier.trainY, simple_classifier.devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature we created in `simple_featurize`, evidently, doesn't have a whole lot of legs. In the next portion of the homework, you'll be designing a few features of your own in the hopes of achieving the highest accuracy possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wIEkYOWO5ClC"
   },
   "source": [
    "## Deliverable 1\n",
    "\n",
    "Your job in this homework is to implement a binary bag-of-words model (i.e., one that assigns a feature value of 1 to each word type that is present in the text); and to brainstorm **3 additional** distinct classes of features, justify why they might help improve the performance *over a bag of words* for this task, implement them in code, and then assess their independent performance on the development data.\n",
    "\n",
    "To show your work: describe your new features and report their performance in the table below; implement the features in the specified `feature1`, `feature2`, and `feature3` functions, and execute each respective classifier to show its performance.  \n",
    "\n",
    "|Feature|Why should it work? (50 words each)|Dev set performance|\n",
    "|---|---|---|\n",
    "|Bag of words| Captures much of the variance between texts by using presence of individual tokens. | 0.776\n",
    "|Feature 1: Text length and uniqueness |  Critics may write different length reviews for positive vs. negative movies, as well as use a more varied vocabulary. For this set of features I tokenize the text, remove punctuation, then take the length of the tokenized text. Then I applied the natural log to reduce skew of outlier length texts. I also took the proportion of unique tokens to the text length. This captures a different dimension of the text than the individual tokens by treating the text as a whole. | 0.508\n",
    "|Feature 2: Bigrams | The bigrams help encode some context from the original text in the features. TO implement this, I used NLTK's bigrams method to create a dictionary where there was a binary indicator for each bigram present. | 0.763\n",
    "|Feature 3: MPQA Subjectivity Lexicon | I leveraged the subjectivity lexicon from MPQA to assign an overall + or - binary label to each text, depending on the majority count of the lexicon's highly subjective words in the text. I expect this to add an additional dimension of sentiment to the text that the bag of words doesn't necessarily capture. (note this is labeled as feature5 below) | 0.659\n",
    "\n",
    "Note that it is not required for your features to actually perform well, but your justification for why it *should* perform better than a bag of words should be defensible.  The most creative features (defined as features that few other students use and that are reasonably well-performing) will receive extra credit for this assignment. Consider the type of data you are working with: what do you look for when writing/reading a movie review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "vVl1zAREekC3"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name, \n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    \n",
    "    # BEGIN SOLUTION\n",
    "    words = [x.lower() for x in nltk.word_tokenize(text)]\n",
    "    words_set = list(set(words))\n",
    "    words_values = np.ones(len(words_set))\n",
    "    feats = dict(zip(words_set, words_values))\n",
    "\n",
    "    return feats\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3AJ5qMBeqmL",
    "outputId": "8fca5300-38b7-4682-8680-5633010dd21e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m######################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m######################################################################\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m bow_classifier \u001b[39m=\u001b[39m Classifier(bag_of_words, L2_regularization_strength\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, min_feature_count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m bow_classifier\u001b[39m.\u001b[39mevaluate()\n",
      "Cell \u001b[0;32mIn [42], line 17\u001b[0m, in \u001b[0;36mClassifier.__init__\u001b[0;34m(self, feature_method, L2_regularization_strength, min_feature_count)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_feature_count\u001b[39m=\u001b[39mmin_feature_count\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainY, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainOrig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess(trainingFile, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevY, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevOrig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(evaluationFile, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestX, _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestOrig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess(testFile, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [42], line 45\u001b[0m, in \u001b[0;36mClassifier.process\u001b[0;34m(self, dataFile, training)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, dataFile, training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     original_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data(dataFile)\n\u001b[0;32m---> 45\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeaturize(original_data)\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m     48\u001b[0m         fid \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[0;32mIn [42], line 38\u001b[0m, in \u001b[0;36mClassifier.featurize\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m featurized_data \u001b[39m=\u001b[39m []\n\u001b[1;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m idd, label, text \u001b[39min\u001b[39;00m data:\n\u001b[0;32m---> 38\u001b[0m     feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_method(text)\n\u001b[1;32m     39\u001b[0m     featurized_data\u001b[39m.\u001b[39mappend((label, feats))\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m featurized_data\n",
      "Cell \u001b[0;32mIn [71], line 6\u001b[0m, in \u001b[0;36mbag_of_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbag_of_words\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Here the `feats` dict should contain the features -- the key should be the feature name, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m# and the value is the feature value.  See `simple_featurize` for an example.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[39m# BEGIN SOLUTION\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     words \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nltk\u001b[39m.\u001b[39;49mword_tokenize(text)]\n\u001b[1;32m      7\u001b[0m     words_set \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(words))\n\u001b[1;32m      8\u001b[0m     words_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(words_set))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39;49mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/nltk/tokenize/destructive.py:179\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    176\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m regexp, substitution \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mENDING_QUOTES:\n\u001b[0;32m--> 179\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39;49msub(substitution, text)\n\u001b[1;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS2:\n\u001b[1;32m    182\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1 \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 \u001b[39m\u001b[39m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "######################################################################\n",
    "\n",
    "bow_classifier = Classifier(bag_of_words, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "bow_classifier.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Original Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "ocPMYhIt4BX0"
   },
   "outputs": [],
   "source": [
    "def feature1(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name, \n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    ''''Implements review length feature'''\n",
    "    feats = {}\n",
    "    words = [x.lower() for x in nltk.word_tokenize(text) if not re.search('[.,!?:;]', x)]\n",
    "    words_set = len(set(words))\n",
    "    prop = words_set / len(words)\n",
    "    feats[\"uniqueness\"] = prop\n",
    "    feats[\"length\"] = np.log(len(words))\n",
    "               \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MAwRwbQ7lVw",
    "outputId": "da38b9d5-d225-4dfd-e914-f5356f40fc79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: feature1, Features: 2, Train accuracy: 0.51700, Dev accuracy: 0.50800\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "######################################################################\n",
    "\n",
    "classifier1 = Classifier(feature1, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "classifier1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "LNlQyjEB4Bwt"
   },
   "outputs": [],
   "source": [
    "def feature2(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name, \n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    '''Implements bigram feature'''\n",
    "    # tokenize text --> list in order of words\n",
    "    words = [x.lower() for x in nltk.word_tokenize(text)]\n",
    "    # split tokens into bigrams\n",
    "    bigrams = list(nltk.bigrams(words))\n",
    "\n",
    "    # Counter object to count unique pairs and store to dict\n",
    "    feats = {k: 1 for k,v in Counter(bigrams).items()}\n",
    "    # print(feats)\n",
    "    # feats = dict(Counter(bigrams))\n",
    "            \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgpuykF67oWZ",
    "outputId": "009fe354-c338-4a4b-8a94-86bcd4901b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: feature2, Features: 122886, Train accuracy: 1.00000, Dev accuracy: 0.76300\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "######################################################################\n",
    "\n",
    "classifier2 = Classifier(feature2, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "classifier2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "FmJKucgn4CEg"
   },
   "outputs": [],
   "source": [
    "# def feature3(text):\n",
    "#     # Here the `feats` dict should contain the features -- the key should be the feature name, \n",
    "#     # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "#     '''Implements capital letter feature'''\n",
    "#     feats = {}\n",
    "#     words = nltk.word_tokenize(text)\n",
    "#     counts = 0\n",
    "#     for w in words:\n",
    "#         if (w == w.upper()) and (w != \"I\"):\n",
    "#             counts += 1\n",
    "#     feats['upper'] = np.log(counts)\n",
    "            \n",
    "#     return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_f--utb7q4l",
    "outputId": "156be8f6-23a3-4e05-fb27-d32cfea7a3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: feature3, Features: 1, Train accuracy: 0.52400, Dev accuracy: 0.52700\n"
     ]
    }
   ],
   "source": [
    "# ######################################################################\n",
    "# ## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "# ######################################################################\n",
    "\n",
    "# classifier3 = Classifier(feature3, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "# classifier3.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Lexicon\n",
    "rawSubjLexicon = []\n",
    "with open(lexiconFile) as f:\n",
    "    for l in f:\n",
    "        rawSubjLexicon.append(l)\n",
    "\n",
    "subjLexicon = {}\n",
    "for x in rawSubjLexicon:\n",
    "    d = dict(re.findall(r'(\\w+)=(\\S+)', x))\n",
    "    # filter out strongsubj and len=1 s\n",
    "    if d['len'] == '1' and d['type'] == 'strongsubj':\n",
    "        subjLexicon[d['word1']] = d['priorpolarity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature5(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name, \n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    '''Implements subjectivity lexicon features'''\n",
    "    feats = {}\n",
    "    words = [x.lower() for x in nltk.word_tokenize(text)]\n",
    "    subjScore = 0\n",
    "     \n",
    "    for w in words:\n",
    "        # look up in lexicon dict\n",
    "        if w in subjLexicon.keys(): \n",
    "            # if positive, add 1 to subjScore\n",
    "            if subjLexicon[w] == 'positive':\n",
    "                subjScore += 1\n",
    "            # if negative, subtract 1 from subjScore\n",
    "            elif subjLexicon[w] == 'negative':\n",
    "                subjScore -= 1\n",
    "        else:\n",
    "            continue\n",
    "    # if overall subjScore is + then overall_positive = 1\n",
    "    # if overall subjScore is -, then overall_negative = 1\n",
    "    \n",
    "    if subjScore > 0:\n",
    "        feats[\"overallPositive\"] = 1\n",
    "    elif subjScore < 0:\n",
    "        feats[\"overallNegative\"] = 1\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: feature5, Features: 2, Train accuracy: 0.66300, Dev accuracy: 0.65900\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "######################################################################\n",
    "\n",
    "classifier5 = Classifier(feature5, L2_regularization_strength=1.0, min_feature_count=1)\n",
    "classifier5.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dg2J1BLgatMP"
   },
   "source": [
    "## Deliverable 2\n",
    "\n",
    "The two cells in \"Combine your features\" will generate a file named `combiner_function_predictions.csv`.\n",
    "\n",
    "Download this file (using e.g. the file manager on the left panel in Colab) and submit this to GradeScope along with your notebook; the 5 students with the highest performance (revealed after the submission deadline) will receive extra credit for this assignment.\n",
    "\n",
    "Please do not change the auto-generated filename!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine your features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEpK5LyMgv5c"
   },
   "source": [
    "Next, let's combine any or all the features you have developed into one big model and make predictions on the test data. There is no exact number/threshold we're looking for, accuracy-wise, but the combiner function should *generally* have a higher accuracy than BoW on its own (assuming your features are adding additional information beyond what BoW is adding). \n",
    "\n",
    "You don't need to edit the following cell, unless you want to change which features are handed off to the \"combined\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "jxKmEqI5JY71"
   },
   "outputs": [],
   "source": [
    "def combiner_function(text):\n",
    "\n",
    "    # Here the `all_feats` dict should contain the features -- the key should be the feature name, \n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    # at the moment, all 4 of: bag of words and your 3 original features are handed off to the combined model\n",
    "    # update the values within [bag_of_words, feature1, feature2, feature3] to change this.\n",
    "    \n",
    "    all_feats={}\n",
    "    for feature in [bag_of_words, feature1, feature2, feature5]:\n",
    "        all_feats.update(feature(text))\n",
    "    return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-tRUFTIdAqT",
    "outputId": "b47331e6-944c-442b-8852-7c2192c473d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: combiner_function, Features: 148962, Train accuracy: 1.00000, Dev accuracy: 0.81300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m big_classifier\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m      9\u001b[0m \u001b[39m# generate .csv file with prediction output on test data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m big_classifier\u001b[39m.\u001b[39;49mpredict()\n",
      "Cell \u001b[0;32mIn [42], line 104\u001b[0m, in \u001b[0;36mClassifier.predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     writer\u001b[39m=\u001b[39mcsv\u001b[39m.\u001b[39mwriter(out)\n\u001b[1;32m    103\u001b[0m     writer\u001b[39m.\u001b[39mwriterow([\u001b[39m\"\u001b[39m\u001b[39mId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mExpected\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mfor\u001b[39;00m idx, data_id \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestX):\n\u001b[1;32m    105\u001b[0m         writer\u001b[39m.\u001b[39mwriterow([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestOrig[idx][\u001b[39m0\u001b[39m], predX[idx]])\n\u001b[1;32m    106\u001b[0m out\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/scipy/sparse/base.py:204\u001b[0m, in \u001b[0;36mspmatrix.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 204\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m[r, :]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/scipy/sparse/_index.py:39\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_intXint(row, col)\n\u001b[1;32m     38\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mslice\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_intXslice(row, col)\n\u001b[1;32m     40\u001b[0m \u001b[39melif\u001b[39;00m col\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_intXarray(row, col)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/scipy/sparse/dok.py:160\u001b[0m, in \u001b[0;36mdok_matrix._get_intXslice\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_intXslice\u001b[39m(\u001b[39mself\u001b[39m, row, col):\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_sliceXslice(\u001b[39mslice\u001b[39;49m(row, row\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m), col)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/scipy/sparse/dok.py:175\u001b[0m, in \u001b[0;36mdok_matrix._get_sliceXslice\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39m# Switch paths only when advantageous\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# (count the iterations in the loops, adjust for complexity)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m shape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m shape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m    174\u001b[0m     \u001b[39m# O(nr*nc) path: loop over <row x col>\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_columnXarray(row_range, col_range)\n\u001b[1;32m    176\u001b[0m \u001b[39m# O(nnz) path: loop over entries of self\u001b[39;00m\n\u001b[1;32m    177\u001b[0m newdok \u001b[39m=\u001b[39m dok_matrix(shape, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cyplan257/lib/python3.10/site-packages/scipy/sparse/dok.py:209\u001b[0m, in \u001b[0;36mdok_matrix._get_columnXarray\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(row):\n\u001b[1;32m    208\u001b[0m     \u001b[39mfor\u001b[39;00m j, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(col):\n\u001b[0;32m--> 209\u001b[0m         v \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m, (r, c), \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    210\u001b[0m         \u001b[39mif\u001b[39;00m v:\n\u001b[1;32m    211\u001b[0m             \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setitem__\u001b[39m(newdok, (i, j), v)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "## Do not edit this block of code, except for the L2_regularization_strength and min_feature_count parameters\n",
    "######################################################################\n",
    "\n",
    "\n",
    "big_classifier = Classifier(combiner_function, L2_regularization_strength=0.6, min_feature_count=1)\n",
    "big_classifier.evaluate()\n",
    "\n",
    "# generate .csv file with prediction output on test data\n",
    "big_classifier.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration: Interrogating classifiers\n",
    "\n",
    "Note: No deliverables are in this section; it's optional. Treat this portion as a useful tool for further understanding the features you worked on and how they affter the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lgyoJm09pqe"
   },
   "source": [
    "Below you will find several ways in which you can interrogate your model to get ideas on ways to improve its performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, let's look at the confusion matrix of its predictions (where we can compare the true labels with the predicted labels). What kinds of mistakes is it making? (While this is mainly helpful in the context of multiclass classification, we can still see if there's a bias toward predicting a specific class in the binary setting as well). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "7ulxd1TosIMV",
    "outputId": "4f3f0503-43e7-4bab-a577-d8d570148a2d"
   },
   "outputs": [],
   "source": [
    "def print_confusion(classifier):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    plot_confusion_matrix(classifier.log_reg, classifier.devX, classifier.devY, ax=ax, xticks_rotation=\"vertical\", values_format=\"d\")\n",
    "    plt.show()\n",
    "\n",
    "print_confusion(big_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPhH4flIuEbx"
   },
   "source": [
    "2. Next, let's look at the features that are most important for each of the classes (ranked by how strong their corresponding coefficient is). Do the features you are defining help in the ways you think they should?  Do sets of successful features suggests others, or complementary features that may provide a different view on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAyGuXIi9pqe",
    "outputId": "36493bf9-33f1-43fd-a779-2f2453477214"
   },
   "outputs": [],
   "source": [
    "big_classifier.printWeights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e80DUsSXu7h9"
   },
   "source": [
    "3. Next, let's look at the individual data points that are the hardest to classify correctly. Does it suggest any features you might create to disentangle them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4uTzwV99pqe"
   },
   "outputs": [],
   "source": [
    "def analyze(classifier):\n",
    "    \n",
    "    probs=classifier.log_reg.predict_proba(classifier.devX)\n",
    "    predicts=classifier.log_reg.predict(classifier.devX)\n",
    "\n",
    "    classes={}\n",
    "    for idx, lab in enumerate(classifier.log_reg.classes_):\n",
    "        classes[lab]=idx\n",
    "\n",
    "    mistakes={}\n",
    "    for i in range(len(probs)):\n",
    "        if predicts[i] != classifier.devY[i]:\n",
    "            predicted_lab_idx=classes[predicts[i]]\n",
    "            mistakes[i]=probs[i][predicted_lab_idx]\n",
    "\n",
    "    frame=[]\n",
    "    sorted_x = sorted(mistakes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_x:\n",
    "        idd=classifier.devOrig[k][0]\n",
    "        text=classifier.devOrig[k][2]\n",
    "        frame.append([idd, v, classifier.devY[k], predicts[k], text])\n",
    "\n",
    "    df=pd.DataFrame(frame, columns=[\"id\", \"P(predicted class confidence)\", \"Human label\", \"Prediction\", \"Text\"]).sort_values(by='Human label')\n",
    "\n",
    "    with option_context('display.max_colwidth', 400):\n",
    "        display(df.head(n=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UXmRhSuzxaJi",
    "outputId": "22da2d22-0a14-4892-c76d-255466ca4091"
   },
   "outputs": [],
   "source": [
    "analyze(big_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cyplan257",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7d4260ce6f682d9d70665d72863e8ecb7f52ad706a59a03223bb09e9d8d92c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
